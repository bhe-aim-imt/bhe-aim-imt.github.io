# DO NOT EDIT, GENERATED AUTOMATICALLY

- id: doi:10.1109/JBHI.2024.3487012
  title: An On-Board Executable Multi-Feature Transfer-Enhanced Fusion Model for Three-Lead
    EEG Sensor-Assisted Depression Diagnosis
  authors:
  - Fuze Tian
  - Haojie Zhang
  - Yang Tan
  - Lixian Zhu
  - Lin Shen
  - Kun Qian
  - Bin Hu
  - "Bj\xF6rn W. Schuller"
  - Yoshiharu Yamamoto
  publisher: IEEE Journal of Biomedical and Health Informatics
  date: '2025-01-01'
  link: https://doi.org/g86jh9
  description: "The development of affective computing and medical electronic technologies\
    \ has led to the emergence of Artificial Intelligence (AI)-based methods for the\
    \ early detection of depression. \nHowever, previous studies have often overlooked\
    \ the necessity for the AI-assisted diagnosis system to be wearable and accessible\
    \ in practical scenarios for depression recognition. \nIn this work, we present\
    \ an on-board executable multi-feature transfer-enhanced fusion model for our\
    \ custom-designed wearable three-lead Electroencephalogram (EEG) sensor, based\
    \ on EEG data collected from 73 depressed patients and 108 healthy controls. \n\
    Experimental results show that the proposed model exhibits low-computational complexity\
    \ (65.0 K parameters), promising Floating-Point Operations (FLOPs) performance\
    \ (25.6 M), real-time processing (1.5 s/execution), and low power consumption\
    \ (320.8 mW). \nFurthermore, it requires only 202.0 KB of Random Access Memory\
    \ (RAM) and 279.6 KB of Read-Only Memory (ROM) when deployed on the EEG sensor.\
    \ \nDespite its low computational and spatial complexity, the model achieves a\
    \ notable classification accuracy of 95.2%, specificity of 94.0%, and sensitivity\
    \ of 96.9% under independent test conditions. \nThese results underscore the potential\
    \ of deploying the model on the wearable three-lead EEG sensor for assisting in\
    \ the diagnosis of depression.\n"
  image: images/JBHI_2024.jpg
  plugin: sources.py
  file: sources.yaml
- id: doi:10.1109/TCE.2024.3514633
  title: A First Look at Generative Artificial Intelligence Based Music Therapy for
    Mental Disorders
  authors:
  - Lin Shen
  - Haojie Zhang
  - Cuiping Zhu
  - Ruobing Li
  - Kun Qian
  - Wei Meng
  - Fuze Tian
  - Bin Hu
  - "Bj\xF6rn W. Schuller"
  - Yoshiharu Yamamoto
  publisher: IEEE Transactions on Consumer Electronics
  date: '2024-12-01'
  link: https://doi.org/g86jjb
  description: "Mental disorders show a rapid increase and cause considerable harm\
    \ to individuals as well as the society in recent decade. \nHence, mental disorders\
    \ have become a serious public health challenge in nowadays society. \nTimely\
    \ treatment of mental disorders plays a critical role for reducing the harm of\
    \ mental illness to individuals and society. \nMusic therapy is a type of non-pharmaceutical\
    \ method in treating such mental disorders. \nHowever, conventional music therapy\
    \ suffers from a number of issues resulting in a lack of popularity. \nThanks\
    \ to the rapid development of Artificial Intelligence (AI), especially the AI\
    \ Generated Content (AIGC), it provides a chance to address these issues. Nevertheless,\
    \ to the best of our knowledge, there is no work investigating music therapy from\
    \ AIGC and closed-loop perspective. \nIn this paper, we summarise some universal\
    \ music therapy methods and discuss their shortages. Then, we indicate some AIGC\
    \ techniques, especially the music generation, for their application in music\
    \ therapy. \nMoreover, we present a closed-loop music therapy system and introduce\
    \ its implementation details. \nFinally, we discuss some challenges in AIGC-based\
    \ music therapy with proposing further research direction, and we suggest the\
    \ potential of this system to become a consumer-grade product for treating mental\
    \ disorders.\n"
  image: images/TCE_2024.jpg
  plugin: sources.py
  file: sources.yaml
- id: doi:10.1109/TCSS.2023.3235079
  title: 'Intelligent Music Intervention for Mental Disorders: Insights and Perspectives'
  authors:
  - Kun Qian
  - Bjorn W. Schuller
  - Xiaohong Guan
  - Bin Hu
  publisher: IEEE Transactions on Computational Social Systems
  date: '2023-02-01'
  link: https://doi.org/gshqt3
  description: "Welcome to the first issue of IEEE Transactions on Computational Social\
    \ Systems (TCSS) of 2023. \nThe past 2022 was again a very productive year, in\
    \ which we have published 159 articles with about 1850 pages in six issues. \n\
    We also received much great and exciting news.\n"
  image: images/TCSS_2023.jpg
  plugin: sources.py
  file: sources.yaml
- id: doi:10.1109/GCCE59613.2023.10315503
  title: Multi-Track Music Generation with WGAN-GP and Attention Mechanisms
  authors:
  - Luyu Chen
  - Lin Shen
  - Dan Yu
  - Zhihua Wang
  - Kun Qian
  - Bin Hu
  - "Bj\xF6rn W. Schuller"
  - Yoshiharu Yamamoto
  publisher: 2023 IEEE 12th Global Conference on Consumer Electronics (GCCE)
  date: '2023-10-10'
  link: https://doi.org/g86jjc
  description: "Music generation with artificial intelligence is a complex and captivating\
    \ task. \nThe utilisation of generative adversarial networks (GANs) has exhibited\
    \ promising outcomes in producing realistic and diverse music compositions. \n\
    In this paper, we propose a model based on Wasserstein GAN with gradient penalty\
    \ (WGAN-GP) for multi-track music generation. \nThis model incorporates self-attention\
    \ and introduces a novel cross-attention mechanism in the generator to enhance\
    \ its expressive capability. \nAdditionally, we transpose all music to C major\
    \ in training to ensure data consistency and quality. \nExperimental results demonstrate\
    \ that our model can produce multi-track music with enhanced rhythm and sound\
    \ characteristics, accelerate convergence, and improve generation quality.\n"
  image: images/GCCE_2023.jpg
  plugin: sources.py
  file: sources.yaml
- id: doi:10.21437/Interspeech.2024-685
  title: 'E-ODN: An Emotion Open Deep Network for Generalised and Adaptive Speech
    Emotion Recognition'
  authors:
  - Liuxian Ma
  - Lin Shen
  - Ruobing Li
  - Haojie Zhang
  - Kun Qian
  - Bin Hu
  - "Bj\xF6rn W. Schuller"
  - Yoshiharu Yamamoto
  publisher: Interspeech 2024
  date: '2024-09-01'
  link: https://doi.org/g86jjf
  description: "Recognising the widest range of emotions possible is a major challenge\
    \ in the task of Speech Emotion Recognition(SER), especially for complex and mixed\
    \ emotions. \nHowever, due to the limited number of emotional types and uneven\
    \ distribution of data within existing datasets, current SER models are typically\
    \ trained and used in a narrow range of emotional types. \nIn this paper, we propose\
    \ the Emotion Open Deep Network(E-ODN) model to address this issue. \nBesides,\
    \ we introduce a novel Open-Set Recognition method that maps sample emotional\
    \ features into a three-dimensional emotional space. \nThe method can infer unknown\
    \ emotions and initialise new type weights, enabling the model to dynamically\
    \ learn and infer emerging emotional types. \nThe empirical results show that\
    \ our recognition model outperforms the state-of-the-art(SOTA) models in dealing\
    \ with multi-type unbalanced data, and it can also perform finer-grained emotion\
    \ recognition.\n"
  image: images/ISP_2024.jpg
  plugin: sources.py
  file: sources.yaml
- id: doi:10.1109/TMC.2025.3547842
  title: An AI-assisted All-in-one Integrated Coronary Artery Disease Diagnosis System
    Using a Portable Heart Sound Sensor with an On-board Executable Lightweight Model
  authors:
  - Haojie Zhang
  - Fuze Tian
  - Yang Tan
  - Lin Shen
  - Jingyu Liu
  - Jie Liu
  - Kun Qian
  - Yalei Han
  - Gong Su
  - Bin Hu
  - "Bj\xF6rn W. Schuller"
  - Yoshiharu Yamamoto
  publisher: IEEE Transactions on Mobile Computing
  date: '2025-01-01'
  link: https://doi.org/g864n5
  description: 'Heart sounds play a crucial role in assessing Coronary Artery Disease
    (CAD). The advancement of Artificial Intelligence (AI) technologies has given
    rise to Computer Audition (CA)-based methods for CAD detection. However, previous
    research has focused primarily on analyzing and modeling heart sound data, overlooking
    practical application scenarios. In this work, we design a pervasive heart sound
    collection device used for high-quality heart sound data acquisition. Moreover,
    we introduce an on-board executable lightweight network tailored for the designed
    portable device, referred to as TYKDModel. Further, heart sound data from 41 CAD
    patients and 22 non-CAD healthy controls are collected using the developed device.
    Experimental results show that the TYKDModel exhibits low-computational complexity,
    with 52.16 K parameters and 5.03 M Floating-Point Operations (FLOPs). When deployed
    on the board, it requires only 1.10 MB of Random Access Memory (RAM) and 236.27
    KB of Read-Only Memory (ROM), and takes around 1.72 seconds to perform a classification.
    Despite the low computational and spatial complexity, the TYKDModel achieves a
    notable classification accuracy of 85.2%, specificity of 88.6%, and sensitivity
    of 82.8% on the board. These results indicate the promising potential of AI-assisted
    all-in-one integrated system for the diagnosis of heart sound-assisted CAD.

    '
  image: images/TMC_2025.jpg
  plugin: sources.py
  file: sources.yaml
- id: doi:10.1109/EMBC40787.2023.10340710
  title: 'Less is More: A Novel Feature Extraction Method for Heart Sound Classification
    via Fractal Transformation'
  authors:
  - Cuiping Zhu
  - Zhonghao Zhao
  - Yang Tan
  - Mengkai Sun
  - Kun Qian
  - Tao Jiang
  - Bin Hu
  - "Bj\xF6rn W. Schuller"
  - Yoshiharu Yamamoto
  publisher: 2023 45th Annual International Conference of the IEEE Engineering in
    Medicine &amp; Biology Society (EMBC)
  date: '2023-07-24'
  link: https://doi.org/g86v6v
  description: 'Cardiovascular diseases (CVDs) are the leading cause of death globally.
    Heart sound signal analysis plays an important role in clinical detection and
    physical examination of CVDs. In recent years, auxiliary diagnosis technology
    of CVDs based on the detection of heart sound signals has become a research hotspot.
    The detection of abnormal heart sounds can provide important clinical information
    to help doctors diagnose and treat heart disease. We propose a new set of fractal
    features-fractal dimension (FD)-as the representation for classification and a
    Support Vector Machine (SVM) as the classification model. The whole process of
    the method includes cutting heart sounds, feature extraction, and classification
    of abnormal heart sounds. We compare the classification results of the heart sound
    waveform (time domain) and the spectrum (frequency domain) based on fractal features.
    Finally, according to the better classification results, we choose the fractal
    features that are most conducive for classification to obtain better classification
    performance. The features we propose outperform the widely used features significantly
    (p < .05 by one-tailed z-test) with a much lower dimension. Clinical relevance-The
    heart sound classification model based on fractal provides a new time-frequency
    analysis method for heart sound signals. A new effective mechanism is proposed
    to explore the relationship between the heart sound acoustic properties and the
    pathology of CVDs. As a non-invasive diagnostic method, this work could supply
    an idea for the preliminary screening of cardiac abnormalities through heart sounds.

    '
  image: images/EMBC_2023_zhu.jpg
  plugin: sources.py
  file: sources.yaml
