# DO NOT EDIT, GENERATED AUTOMATICALLY

- id: doi:10.1109/JBHI.2024.3487012
  title: An On-Board Executable Multi-Feature Transfer-Enhanced Fusion Model for Three-Lead
    EEG Sensor-Assisted Depression Diagnosis
  authors:
  - Fuze Tian
  - Haojie Zhang
  - Yang Tan
  - Lixian Zhu
  - Lin Shen
  - Kun Qian
  - Bin Hu
  - "Bj\xF6rn W. Schuller"
  - Yoshiharu Yamamoto
  publisher: IEEE Journal of Biomedical and Health Informatics
  date: '2025-01-01'
  link: https://doi.org/g86jh9
  description: "The development of affective computing and medical electronic technologies\
    \ has led to the emergence of Artificial Intelligence (AI)-based methods for the\
    \ early detection of depression. \nHowever, previous studies have often overlooked\
    \ the necessity for the AI-assisted diagnosis system to be wearable and accessible\
    \ in practical scenarios for depression recognition. \nIn this work, we present\
    \ an on-board executable multi-feature transfer-enhanced fusion model for our\
    \ custom-designed wearable three-lead Electroencephalogram (EEG) sensor, based\
    \ on EEG data collected from 73 depressed patients and 108 healthy controls. \n\
    Experimental results show that the proposed model exhibits low-computational complexity\
    \ (65.0 K parameters), promising Floating-Point Operations (FLOPs) performance\
    \ (25.6 M), real-time processing (1.5 s/execution), and low power consumption\
    \ (320.8 mW). \nFurthermore, it requires only 202.0 KB of Random Access Memory\
    \ (RAM) and 279.6 KB of Read-Only Memory (ROM) when deployed on the EEG sensor.\
    \ \nDespite its low computational and spatial complexity, the model achieves a\
    \ notable classification accuracy of 95.2%, specificity of 94.0%, and sensitivity\
    \ of 96.9% under independent test conditions. \nThese results underscore the potential\
    \ of deploying the model on the wearable three-lead EEG sensor for assisting in\
    \ the diagnosis of depression.\n"
  image: images/JBHI_2024.jpg
  plugin: sources.py
  file: sources.yaml
- id: doi:10.1109/TCE.2024.3514633
  title: A First Look at Generative Artificial Intelligence Based Music Therapy for
    Mental Disorders
  authors:
  - Lin Shen
  - Haojie Zhang
  - Cuiping Zhu
  - Ruobing Li
  - Kun Qian
  - Wei Meng
  - Fuze Tian
  - Bin Hu
  - "Bj\xF6rn W. Schuller"
  - Yoshiharu Yamamoto
  publisher: IEEE Transactions on Consumer Electronics
  date: '2024-12-01'
  link: https://doi.org/g86jjb
  description: "Mental disorders show a rapid increase and cause considerable harm\
    \ to individuals as well as the society in recent decade. \nHence, mental disorders\
    \ have become a serious public health challenge in nowadays society. \nTimely\
    \ treatment of mental disorders plays a critical role for reducing the harm of\
    \ mental illness to individuals and society. \nMusic therapy is a type of non-pharmaceutical\
    \ method in treating such mental disorders. \nHowever, conventional music therapy\
    \ suffers from a number of issues resulting in a lack of popularity. \nThanks\
    \ to the rapid development of Artificial Intelligence (AI), especially the AI\
    \ Generated Content (AIGC), it provides a chance to address these issues. Nevertheless,\
    \ to the best of our knowledge, there is no work investigating music therapy from\
    \ AIGC and closed-loop perspective. \nIn this paper, we summarise some universal\
    \ music therapy methods and discuss their shortages. Then, we indicate some AIGC\
    \ techniques, especially the music generation, for their application in music\
    \ therapy. \nMoreover, we present a closed-loop music therapy system and introduce\
    \ its implementation details. \nFinally, we discuss some challenges in AIGC-based\
    \ music therapy with proposing further research direction, and we suggest the\
    \ potential of this system to become a consumer-grade product for treating mental\
    \ disorders.\n"
  image: images/TCE_2024.jpg
  plugin: sources.py
  file: sources.yaml
- id: doi:10.1109/TCSS.2023.3235079
  title: 'Intelligent Music Intervention for Mental Disorders: Insights and Perspectives'
  authors:
  - Kun Qian
  - Bjorn W. Schuller
  - Xiaohong Guan
  - Bin Hu
  publisher: IEEE Transactions on Computational Social Systems
  date: '2023-02-01'
  link: https://doi.org/gshqt3
  description: "Welcome to the first issue of IEEE Transactions on Computational Social\
    \ Systems (TCSS) of 2023. \nThe past 2022 was again a very productive year, in\
    \ which we have published 159 articles with about 1850 pages in six issues. \n\
    We also received much great and exciting news.\n"
  image: images/TCSS_2023.jpg
  plugin: sources.py
  file: sources.yaml
- id: doi:10.1109/GCCE59613.2023.10315503
  title: Multi-Track Music Generation with WGAN-GP and Attention Mechanisms
  authors:
  - Luyu Chen
  - Lin Shen
  - Dan Yu
  - Zhihua Wang
  - Kun Qian
  - Bin Hu
  - "Bj\xF6rn W. Schuller"
  - Yoshiharu Yamamoto
  publisher: 2023 IEEE 12th Global Conference on Consumer Electronics (GCCE)
  date: '2023-10-10'
  link: https://doi.org/g86jjc
  description: "Music generation with artificial intelligence is a complex and captivating\
    \ task. \nThe utilisation of generative adversarial networks (GANs) has exhibited\
    \ promising outcomes in producing realistic and diverse music compositions. \n\
    In this paper, we propose a model based on Wasserstein GAN with gradient penalty\
    \ (WGAN-GP) for multi-track music generation. \nThis model incorporates self-attention\
    \ and introduces a novel cross-attention mechanism in the generator to enhance\
    \ its expressive capability. \nAdditionally, we transpose all music to C major\
    \ in training to ensure data consistency and quality. \nExperimental results demonstrate\
    \ that our model can produce multi-track music with enhanced rhythm and sound\
    \ characteristics, accelerate convergence, and improve generation quality.\n"
  image: images/GCCE_2023.jpg
  plugin: sources.py
  file: sources.yaml
- id: doi:10.21437/Interspeech.2024-685
  title: 'E-ODN: An Emotion Open Deep Network for Generalised and Adaptive Speech
    Emotion Recognition'
  authors:
  - Liuxian Ma
  - Lin Shen
  - Ruobing Li
  - Haojie Zhang
  - Kun Qian
  - Bin Hu
  - "Bj\xF6rn W. Schuller"
  - Yoshiharu Yamamoto
  publisher: Interspeech 2024
  date: '2024-09-01'
  link: https://doi.org/g86jjf
  description: "Recognising the widest range of emotions possible is a major challenge\
    \ in the task of Speech Emotion Recognition(SER), especially for complex and mixed\
    \ emotions. \nHowever, due to the limited number of emotional types and uneven\
    \ distribution of data within existing datasets, current SER models are typically\
    \ trained and used in a narrow range of emotional types. \nIn this paper, we propose\
    \ the Emotion Open Deep Network(E-ODN) model to address this issue. \nBesides,\
    \ we introduce a novel Open-Set Recognition method that maps sample emotional\
    \ features into a three-dimensional emotional space. \nThe method can infer unknown\
    \ emotions and initialise new type weights, enabling the model to dynamically\
    \ learn and infer emerging emotional types. \nThe empirical results show that\
    \ our recognition model outperforms the state-of-the-art(SOTA) models in dealing\
    \ with multi-type unbalanced data, and it can also perform finer-grained emotion\
    \ recognition.\n"
  image: images/ISP_2024.jpg
  plugin: sources.py
  file: sources.yaml
